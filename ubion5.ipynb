{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ICh43289-9PseXHGeeJsG2g8yJi532BT",
      "authorship_tag": "ABX9TyM60eKrHEKYnmh+KOJhdwFe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chajunhyeop/-/blob/main/ubion5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#신경망\n",
        "##분류예측"
      ],
      "metadata": {
        "id": "rALxdRgXa740"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Ashopping.csv\",encoding = 'cp949')"
      ],
      "metadata": {
        "id": "CJKxuW73bl38"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbTqzALMcA_U",
        "outputId": "050d2775-b46b-43e6-9a51-693b3096f974"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   고객ID       1000 non-null   int64  \n",
            " 1   이탈여부       1000 non-null   int64  \n",
            " 2   총매출액       1000 non-null   int64  \n",
            " 3   구매금액대      1000 non-null   int64  \n",
            " 4   방문빈도       1000 non-null   int64  \n",
            " 5   1회 평균매출액   1000 non-null   int64  \n",
            " 6   할인권 사용 횟수  1000 non-null   int64  \n",
            " 7   총 할인 금액    1000 non-null   int64  \n",
            " 8   고객등급       1000 non-null   int64  \n",
            " 9   구매유형       1000 non-null   int64  \n",
            " 10  클레임접수여부    1000 non-null   int64  \n",
            " 11  구매카테고리수    1000 non-null   int64  \n",
            " 12  거주지역       1000 non-null   int64  \n",
            " 13  성별         1000 non-null   int64  \n",
            " 14  고객 나이대     1000 non-null   int64  \n",
            " 15  거래기간       1000 non-null   int64  \n",
            " 16  할인민감여부     1000 non-null   int64  \n",
            " 17  Recency    1000 non-null   int64  \n",
            " 18  Frequency  1000 non-null   int64  \n",
            " 19  Monetary   1000 non-null   int64  \n",
            " 20  평균 구매주기    1000 non-null   float64\n",
            "dtypes: float64(1), int64(20)\n",
            "memory usage: 164.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-M3vcMZcCUI",
        "outputId": "07bd6ea2-4185-4c4b-a91a-c21b0c3b8701"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "고객ID         0\n",
              "이탈여부         0\n",
              "총매출액         0\n",
              "구매금액대        0\n",
              "방문빈도         0\n",
              "1회 평균매출액     0\n",
              "할인권 사용 횟수    0\n",
              "총 할인 금액      0\n",
              "고객등급         0\n",
              "구매유형         0\n",
              "클레임접수여부      0\n",
              "구매카테고리수      0\n",
              "거주지역         0\n",
              "성별           0\n",
              "고객 나이대       0\n",
              "거래기간         0\n",
              "할인민감여부       0\n",
              "Recency      0\n",
              "Frequency    0\n",
              "Monetary     0\n",
              "평균 구매주기      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "p0Zy8uwZcEXm",
        "outputId": "5e769db3-c574-4a06-d4f4-b47c14444ab5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              고객ID         이탈여부          총매출액        구매금액대        방문빈도  \\\n",
              "count  1000.000000  1000.000000  1.000000e+03  1000.000000  1000.00000   \n",
              "mean    500.500000     0.300000  5.858013e+06     0.700000    22.91100   \n",
              "std     288.819436     0.458487  5.812815e+06     0.781416    19.08217   \n",
              "min       1.000000     0.000000  1.886100e+06     0.000000     1.00000   \n",
              "25%     250.750000     0.000000  2.815905e+06     0.000000    10.75000   \n",
              "50%     500.500000     0.000000  4.092145e+06     0.500000    18.00000   \n",
              "75%     750.250000     1.000000  6.545392e+06     1.000000    28.00000   \n",
              "max    1000.000000     1.000000  6.759576e+07     2.000000   155.00000   \n",
              "\n",
              "           1회 평균매출액    할인권 사용 횟수        총 할인 금액         고객등급         구매유형  \\\n",
              "count  1.000000e+03  1000.000000    1000.000000  1000.000000  1000.000000   \n",
              "mean   3.521024e+05    16.027000  292371.670000     1.546000     2.656000   \n",
              "std    3.124636e+05     8.341334  111937.501042     0.498129     1.046307   \n",
              "min    2.708200e+04     1.000000    3750.000000     1.000000     1.000000   \n",
              "25%    1.631242e+05     9.000000  261686.250000     1.000000     2.000000   \n",
              "50%    2.582080e+05    17.000000  347500.000000     2.000000     2.000000   \n",
              "75%    4.268310e+05    23.000000  365400.000000     2.000000     4.000000   \n",
              "max    2.798500e+06    30.000000  400600.000000     2.000000     4.000000   \n",
              "\n",
              "       ...      구매카테고리수         거주지역           성별       고객 나이대         거래기간  \\\n",
              "count  ...  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
              "mean   ...     5.217000     5.147000     0.189000     3.964000  3495.891000   \n",
              "std    ...     2.224153     1.169084     0.391705     1.078827   965.966194   \n",
              "min    ...     1.000000     1.000000     0.000000     2.000000   827.000000   \n",
              "25%    ...     3.000000     4.000000     0.000000     3.000000  2871.000000   \n",
              "50%    ...     5.000000     5.000000     0.000000     4.000000  3836.000000   \n",
              "75%    ...     7.000000     6.000000     0.000000     5.000000  4207.250000   \n",
              "max    ...     9.000000     7.000000     1.000000     7.000000  5334.000000   \n",
              "\n",
              "            할인민감여부      Recency    Frequency     Monetary      평균 구매주기  \n",
              "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
              "mean      0.400000     4.925000     2.289000     4.129000   266.880824  \n",
              "std       0.490143     1.744253     1.669811     1.560383   254.077398  \n",
              "min       0.000000     1.000000     1.000000     1.000000    13.980645  \n",
              "25%       0.000000     4.000000     1.000000     3.000000   111.957671  \n",
              "50%       0.000000     5.000000     2.000000     4.000000   191.469697  \n",
              "75%       1.000000     7.000000     3.000000     6.000000   324.386218  \n",
              "max       1.000000     7.000000     7.000000     7.000000  1956.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5db762db-e08a-4b1a-9d15-94028464652a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>고객ID</th>\n",
              "      <th>이탈여부</th>\n",
              "      <th>총매출액</th>\n",
              "      <th>구매금액대</th>\n",
              "      <th>방문빈도</th>\n",
              "      <th>1회 평균매출액</th>\n",
              "      <th>할인권 사용 횟수</th>\n",
              "      <th>총 할인 금액</th>\n",
              "      <th>고객등급</th>\n",
              "      <th>구매유형</th>\n",
              "      <th>...</th>\n",
              "      <th>구매카테고리수</th>\n",
              "      <th>거주지역</th>\n",
              "      <th>성별</th>\n",
              "      <th>고객 나이대</th>\n",
              "      <th>거래기간</th>\n",
              "      <th>할인민감여부</th>\n",
              "      <th>Recency</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>Monetary</th>\n",
              "      <th>평균 구매주기</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>500.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>5.858013e+06</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>22.91100</td>\n",
              "      <td>3.521024e+05</td>\n",
              "      <td>16.027000</td>\n",
              "      <td>292371.670000</td>\n",
              "      <td>1.546000</td>\n",
              "      <td>2.656000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.217000</td>\n",
              "      <td>5.147000</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>3.964000</td>\n",
              "      <td>3495.891000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>4.925000</td>\n",
              "      <td>2.289000</td>\n",
              "      <td>4.129000</td>\n",
              "      <td>266.880824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>288.819436</td>\n",
              "      <td>0.458487</td>\n",
              "      <td>5.812815e+06</td>\n",
              "      <td>0.781416</td>\n",
              "      <td>19.08217</td>\n",
              "      <td>3.124636e+05</td>\n",
              "      <td>8.341334</td>\n",
              "      <td>111937.501042</td>\n",
              "      <td>0.498129</td>\n",
              "      <td>1.046307</td>\n",
              "      <td>...</td>\n",
              "      <td>2.224153</td>\n",
              "      <td>1.169084</td>\n",
              "      <td>0.391705</td>\n",
              "      <td>1.078827</td>\n",
              "      <td>965.966194</td>\n",
              "      <td>0.490143</td>\n",
              "      <td>1.744253</td>\n",
              "      <td>1.669811</td>\n",
              "      <td>1.560383</td>\n",
              "      <td>254.077398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.886100e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.708200e+04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3750.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>827.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.980645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>250.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.815905e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.75000</td>\n",
              "      <td>1.631242e+05</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>261686.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2871.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>111.957671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>500.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.092145e+06</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>18.00000</td>\n",
              "      <td>2.582080e+05</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>347500.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3836.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>191.469697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>750.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.545392e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.00000</td>\n",
              "      <td>4.268310e+05</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>365400.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4207.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>324.386218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.759576e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>155.00000</td>\n",
              "      <td>2.798500e+06</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>400600.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5334.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1956.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5db762db-e08a-4b1a-9d15-94028464652a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5db762db-e08a-4b1a-9d15-94028464652a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5db762db-e08a-4b1a-9d15-94028464652a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "vE2BSvHTcFK9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#분류예측\n",
        "\n",
        "#변수선택\n",
        "X = df[[\"총매출액\", \"1회 평균매출액\", \"평균 구매주기\", \"거래기간\", \"구매금액대\"]]\n",
        "Y = df[\"할인민감여부\"]\n",
        "\n",
        "#데이터 분할(train, test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "#데이터 전처리\n",
        "ct = ColumnTransformer([('scaling', StandardScaler(), [\"총매출액\", \"1회 평균매출액\", \"평균 구매주기\", \"거래기간\"]),\n",
        "                        (\"onehot\", OneHotEncoder(sparse = False), [\"구매금액대\"])])\n",
        "ct.fit(X_train)\n",
        "\n",
        "X_train= ct.transform(X_train)\n",
        "X_test= ct.transform(X_test)\n",
        "\n",
        "#오버샘플링\n",
        "from imblearn.over_sampling import SMOTE #Synthetic minority over-sampling techniqe\n",
        "\n",
        "X_train, Y_train = SMOTE(random_state = 0).fit_resample(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Vb9CgjIVc327"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델링\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "z-soUEPVibiP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = MLPClassifier(random_state=0, alpha = 0.001, hidden_layer_sizes = [50])\n",
        "\n",
        "#모형 학습\n",
        "nn_model.fit(X_train, Y_train)\n",
        "\n",
        "#예측\n",
        "Y_pred = nn_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htkFZre9gZpy",
        "outputId": "622f0de8-8113-4b0d-b541-33ca9d5c33dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxVoFS8FhbAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과값 보고\n",
        "print(\"Y 예측값 \\n\", Y_pred)\n",
        "print(\"accuracy(train) : {:.3f}\".format(nn_model.score(X_train, Y_train)))\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sce7oyqYhIxJ",
        "outputId": "a1d92d58-bbd7-43a7-db06-6b5dee90a2ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y 예측값 \n",
            " [1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
            " 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0\n",
            " 0 0 0 0]\n",
            "accuracy(train) : 0.889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91       177\n",
            "           1       0.85      0.89      0.87       123\n",
            "\n",
            "    accuracy                           0.89       300\n",
            "   macro avg       0.89      0.89      0.89       300\n",
            "weighted avg       0.89      0.89      0.89       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#변수선택\n",
        "X = df[df.이탈여부 == 0][[\"방문빈도\", \"총 할인 금액\", \"고객등급\", \"구매유형\", \"거래기간\", \"할인민감여부\", \"평균 구매주기\"]]\n",
        "Y = df[df.이탈여부 == 0][\"1회 평균매출액\"]\n",
        "\n",
        "#데이터 분할(train, test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "#데이터 전처리\n",
        "ct = ColumnTransformer([('scaling', StandardScaler(), [\"방문빈도\", \"총 할인 금액\", \"거래기간\", \"평균 구매주기\"]),\n",
        "                        (\"onehot\", OneHotEncoder(sparse = False), [\"고객등급\", \"구매유형\", \"할인민감여부\"])])\n",
        "ct.fit(X_train)\n",
        "\n",
        "X_train= ct.transform(X_train)\n",
        "X_test= ct.transform(X_test)\n"
      ],
      "metadata": {
        "id": "FmLjRGkkpSgp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "#모델 생성\n",
        "nn_reg_model = MLPRegressor(random_state = 0, alpha = 1, max_iter = 1000,\n",
        "                            hidden_layer_sizes = [50,50])\n",
        "\n",
        "#모형학습 및 예측\n",
        "nn_reg_model.fit(X_train, Y_train)\n",
        "Y_pred = nn_reg_model.predict(X_test)\n",
        "\n",
        "#결과값 보고\n",
        "print(\"Y predict value : \\n\", Y_pred)\n",
        "print(\"train accuracy : {:.3f}\".format(nn_reg_model.score(X_train, Y_train)))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
        "print(\"RMSE : {:.3f}\".format(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCmDFCuNquFe",
        "outputId": "61efdbad-18f2-4b05-a2ae-6b8ca1cb61ab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y predict value : \n",
            " [367567.22799569 291986.7171292  286542.39507057 470299.18982825\n",
            " 199015.43022523 314985.16674704 120385.261673    99679.50744792\n",
            " 217207.85032309 321283.5694424  322281.24636508 139031.08090941\n",
            " 172479.30691299 307474.28058998 410674.7673535  282802.14200659\n",
            " 314022.43590656 344082.61534343 266080.18516834 299527.46258462\n",
            " 417918.96528793 213628.82138014 325703.16436337 276841.23973322\n",
            "  83289.89193415 370306.40166324 392255.59988171 148021.81268408\n",
            " 135257.54780785 288250.40948644 329672.79002503 409898.41100752\n",
            " 238134.15585775 368306.05176262 275290.22641391 239081.40629288\n",
            " 266321.69500888 375448.00373975 246605.1330584  641448.06611111\n",
            " 336904.01756403 215252.99856889 241609.33155848 271063.86770618\n",
            " 236907.37454933 382141.50786421 141280.68282403 289125.50608539\n",
            " 298377.15265302 346302.09403242 253397.19897089 508363.2921946\n",
            "  55430.52886374 316398.6845584  307992.35916116 291458.05176895\n",
            " 365830.87156821 337348.7566333  283210.3790915  258622.02741059\n",
            " 321376.87461064 327403.5219942  223207.07109362 339375.24930473\n",
            " 235633.20353306 207937.38459674 262238.13165728 155176.57248646\n",
            " 446908.94216759 158813.06040685 324047.59496836 252640.34325201\n",
            " 249188.03432076 255476.98860462 135204.18190746 486863.31488025\n",
            " 389836.25584169 417264.89960339 137349.62110706 330482.67927447\n",
            " 202882.37492681 244085.71728165 216194.80179372 178187.54506876\n",
            " 326307.74557151 334835.24310067 259056.39725013 318455.2747672\n",
            " 245978.7402989  349977.88045537 313576.00711254 360034.97890785\n",
            " 302180.47800664 346414.147532   237623.24093074 537825.48286654\n",
            " 306899.04560765 198016.87086714 356756.250312   126411.60509786\n",
            " 222199.09532434 293326.26886908 357988.60770913 274905.50147079\n",
            " 321045.37222521 308870.73491254 328625.82189502 200975.70277517\n",
            " 296192.52973971 279928.30765362 260548.00636601 243793.66083518\n",
            " 342931.62784114 486251.93814507 263093.75393189 222741.17780968\n",
            " 280110.46803518 314221.44235756 237481.55329132 271619.53638204\n",
            " 356806.58975663 367708.28247153 232120.08009347 279820.78777821\n",
            " 336140.0816819  301035.34267013 196964.58034718 242703.54496087\n",
            " 382656.27941644 264746.6531743   74865.40367927 229185.42533768\n",
            " 449451.21775471 333497.22792232 181490.12700764 308568.97923415\n",
            " 162126.67867317 273979.725792   312484.58403589 268972.60081153\n",
            " 294422.26870008 280549.89684759 369158.98151701 236824.03178162\n",
            " 191405.47832004 351443.85315144 298057.17180239 366323.17194185\n",
            " 160087.98542242 289201.47993591 187648.53842493 275254.96461994\n",
            " 296878.85455016 351165.94366769 685012.47921711 197831.35625512\n",
            "    817.42017899 336795.26572669 307319.33036176 286538.74627755\n",
            " 356601.98981613 413427.13794709 399347.35085261 181438.83136968\n",
            " 229242.10355842 330888.72112284 326911.57257259 213774.88283495\n",
            " 372421.41967877 243911.48617397   1134.30582295 251342.72805545\n",
            " 149121.8720192  518450.65557447 163722.93239689 330273.5210797\n",
            " 628305.94584286 229238.61156581 308547.9272714  150580.26882881\n",
            " 557029.72398692 782868.63100081 389620.35786206 424001.85956249\n",
            " 261503.41228481 201832.48696299 311830.67263387 308643.85612775\n",
            "  63366.06569213 343396.35371872 309710.08763841 315943.40002105\n",
            " 590729.84011205  81729.53183386 282024.21237733 289056.00731604\n",
            " 329795.69550524 107196.24435223 373365.59284941 119783.54874409\n",
            " 474729.87515126 108723.20464901 294099.46394641 263585.28216134\n",
            " 282962.56218265 223533.52354009 317057.78433315 328600.46139415\n",
            " 342669.79765667 293334.82175315]\n",
            "train accuracy : 0.300\n",
            "RMSE : 227578.429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#딥러닝\n",
        "##경고문 제거"
      ],
      "metadata": {
        "id": "ZR0l7ZTAuRb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "E-jGhMxHuaH5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#변수선택\n",
        "X = df[[\"총매출액\", \"1회 평균매출액\", \"평균 구매주기\", \"거래기간\", \"구매금액대\"]]\n",
        "Y = df[\"할인민감여부\"]\n",
        "\n",
        "#데이터 분할(train, test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "#데이터 전처리\n",
        "ct = ColumnTransformer([('scaling', StandardScaler(), [\"총매출액\", \"1회 평균매출액\", \"평균 구매주기\", \"거래기간\"]),\n",
        "                        (\"onehot\", OneHotEncoder(sparse = False), [\"구매금액대\"])])\n",
        "ct.fit(X_train)\n",
        "\n",
        "X_train= ct.transform(X_train)\n",
        "X_test= ct.transform(X_test)\n",
        "\n",
        "#오버샘플링\n",
        "from imblearn.over_sampling import SMOTE #Synthetic minority over-sampling techniqe\n",
        "\n",
        "X_train, Y_train = SMOTE(random_state = 0).fit_resample(X_train, Y_train)"
      ],
      "metadata": {
        "id": "wRYPEEjjueRe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential  #노드에 레이어가 생기는 데 신경망에는 레이어가 있다.\n",
        "#그리고 노드가 있는데 이런 레이더들이 이어져서 아웃풋으로 이어진다.\n",
        "#시퀀셜을 순차적으로 가는 것을 만드는 것이다.\n",
        "from keras.layers import Dense, Activation#dense는 노드들의 수이다.\n",
        "#노드의 밀도를 정해주는데 밀도가 높다는 것은 그 중에서 계산이 많다는 것이다.\n",
        "from keras.metrics import Accuracy\n",
        "\n",
        "#시드값 설정\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "#모형생성\n",
        "model = keras.models.Sequential()#순차적인 모형을 형성\n",
        "model.add(keras.layers.Dense(64, input_dim=7, activation = \"relu\")) #레이어나 밀도를 추가한다.\n",
        "#input dim= 7 -> 7차원의 신경망을 만들겠다. -> 밀도는 64이다. 하이퍼파라미터 지정 활성화함수 (activation)\n",
        "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
        "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "#모형학습\n",
        "#불순도 확인 모델이 얼마나 불순도를 없앴는지, 불순도는 적합성과 반비례관계를 가진다.\n",
        "#메트릭스는 적합도를 보여준다\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split = 0.2, epochs = 100, \n",
        "                    batch_size = 64, verbose = 2)\n",
        "#변수를 지정하기 위해서 지정 두개의 훈련셋을 넣어서 100번의 계산을 시도한다.\n",
        "#1부터 시작 - 100까지 계산한다. 대신 계산이 오래걸림\n",
        "#벤치 사이즈와 벌보스는 그냥 디폴트값으로 사용하면 된다. \n",
        "#적정한 에폭을 결정하는것이 중요하다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo4XAUjMupsU",
        "outputId": "b90485e6-73ee-4b58-8093-0716dd6954d7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 - 1s - loss: 0.6829 - accuracy: 0.5888 - val_loss: 0.6856 - val_accuracy: 0.6529 - 781ms/epoch - 71ms/step\n",
            "Epoch 2/100\n",
            "11/11 - 0s - loss: 0.5836 - accuracy: 0.8254 - val_loss: 0.6330 - val_accuracy: 0.6471 - 30ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "11/11 - 0s - loss: 0.5174 - accuracy: 0.8284 - val_loss: 0.6003 - val_accuracy: 0.6765 - 47ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "11/11 - 0s - loss: 0.4679 - accuracy: 0.8328 - val_loss: 0.5588 - val_accuracy: 0.7353 - 38ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "11/11 - 0s - loss: 0.4343 - accuracy: 0.8595 - val_loss: 0.5102 - val_accuracy: 0.8118 - 34ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "11/11 - 0s - loss: 0.4104 - accuracy: 0.8624 - val_loss: 0.5205 - val_accuracy: 0.7882 - 32ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "11/11 - 0s - loss: 0.3902 - accuracy: 0.8713 - val_loss: 0.4881 - val_accuracy: 0.8235 - 34ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "11/11 - 0s - loss: 0.3756 - accuracy: 0.8802 - val_loss: 0.4970 - val_accuracy: 0.8176 - 32ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "11/11 - 0s - loss: 0.3606 - accuracy: 0.8905 - val_loss: 0.4988 - val_accuracy: 0.8235 - 31ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "11/11 - 0s - loss: 0.3481 - accuracy: 0.8876 - val_loss: 0.4776 - val_accuracy: 0.8412 - 30ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "11/11 - 0s - loss: 0.3354 - accuracy: 0.8964 - val_loss: 0.5106 - val_accuracy: 0.8235 - 34ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "11/11 - 0s - loss: 0.3230 - accuracy: 0.8994 - val_loss: 0.4591 - val_accuracy: 0.8529 - 30ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "11/11 - 0s - loss: 0.3110 - accuracy: 0.9038 - val_loss: 0.4816 - val_accuracy: 0.8471 - 33ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "11/11 - 0s - loss: 0.3008 - accuracy: 0.9038 - val_loss: 0.4843 - val_accuracy: 0.8471 - 33ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "11/11 - 0s - loss: 0.2923 - accuracy: 0.9112 - val_loss: 0.4878 - val_accuracy: 0.8529 - 48ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "11/11 - 0s - loss: 0.2855 - accuracy: 0.9172 - val_loss: 0.4796 - val_accuracy: 0.8529 - 34ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "11/11 - 0s - loss: 0.2792 - accuracy: 0.9172 - val_loss: 0.4837 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "11/11 - 0s - loss: 0.2729 - accuracy: 0.9216 - val_loss: 0.4902 - val_accuracy: 0.8588 - 28ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "11/11 - 0s - loss: 0.2664 - accuracy: 0.9157 - val_loss: 0.4760 - val_accuracy: 0.8588 - 40ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "11/11 - 0s - loss: 0.2629 - accuracy: 0.9186 - val_loss: 0.4975 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "11/11 - 0s - loss: 0.2586 - accuracy: 0.9216 - val_loss: 0.4753 - val_accuracy: 0.8529 - 53ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "11/11 - 0s - loss: 0.2545 - accuracy: 0.9216 - val_loss: 0.4969 - val_accuracy: 0.8529 - 37ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "11/11 - 0s - loss: 0.2500 - accuracy: 0.9216 - val_loss: 0.4686 - val_accuracy: 0.8588 - 39ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "11/11 - 0s - loss: 0.2481 - accuracy: 0.9186 - val_loss: 0.4818 - val_accuracy: 0.8588 - 32ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "11/11 - 0s - loss: 0.2481 - accuracy: 0.9186 - val_loss: 0.4760 - val_accuracy: 0.8588 - 49ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "11/11 - 0s - loss: 0.2421 - accuracy: 0.9201 - val_loss: 0.4532 - val_accuracy: 0.8588 - 32ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "11/11 - 0s - loss: 0.2418 - accuracy: 0.9246 - val_loss: 0.4800 - val_accuracy: 0.8588 - 33ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "11/11 - 0s - loss: 0.2370 - accuracy: 0.9260 - val_loss: 0.4627 - val_accuracy: 0.8588 - 34ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "11/11 - 0s - loss: 0.2360 - accuracy: 0.9172 - val_loss: 0.4610 - val_accuracy: 0.8588 - 35ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "11/11 - 0s - loss: 0.2324 - accuracy: 0.9275 - val_loss: 0.4712 - val_accuracy: 0.8529 - 31ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "11/11 - 0s - loss: 0.2309 - accuracy: 0.9290 - val_loss: 0.4492 - val_accuracy: 0.8588 - 35ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "11/11 - 0s - loss: 0.2293 - accuracy: 0.9290 - val_loss: 0.4589 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "11/11 - 0s - loss: 0.2291 - accuracy: 0.9305 - val_loss: 0.4483 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "11/11 - 0s - loss: 0.2252 - accuracy: 0.9290 - val_loss: 0.4475 - val_accuracy: 0.8588 - 35ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "11/11 - 0s - loss: 0.2247 - accuracy: 0.9290 - val_loss: 0.4419 - val_accuracy: 0.8588 - 37ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "11/11 - 0s - loss: 0.2240 - accuracy: 0.9246 - val_loss: 0.4333 - val_accuracy: 0.8647 - 35ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "11/11 - 0s - loss: 0.2223 - accuracy: 0.9305 - val_loss: 0.4677 - val_accuracy: 0.8529 - 52ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "11/11 - 0s - loss: 0.2193 - accuracy: 0.9290 - val_loss: 0.4230 - val_accuracy: 0.8588 - 33ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "11/11 - 0s - loss: 0.2183 - accuracy: 0.9305 - val_loss: 0.4455 - val_accuracy: 0.8588 - 34ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "11/11 - 0s - loss: 0.2165 - accuracy: 0.9334 - val_loss: 0.4343 - val_accuracy: 0.8647 - 29ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "11/11 - 0s - loss: 0.2149 - accuracy: 0.9334 - val_loss: 0.4333 - val_accuracy: 0.8588 - 32ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "11/11 - 0s - loss: 0.2139 - accuracy: 0.9320 - val_loss: 0.4404 - val_accuracy: 0.8588 - 49ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "11/11 - 0s - loss: 0.2145 - accuracy: 0.9260 - val_loss: 0.4200 - val_accuracy: 0.8588 - 32ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "11/11 - 0s - loss: 0.2120 - accuracy: 0.9349 - val_loss: 0.4548 - val_accuracy: 0.8529 - 33ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "11/11 - 0s - loss: 0.2110 - accuracy: 0.9334 - val_loss: 0.4268 - val_accuracy: 0.8647 - 31ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "11/11 - 0s - loss: 0.2082 - accuracy: 0.9364 - val_loss: 0.4381 - val_accuracy: 0.8529 - 30ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "11/11 - 0s - loss: 0.2085 - accuracy: 0.9364 - val_loss: 0.4311 - val_accuracy: 0.8588 - 47ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "11/11 - 0s - loss: 0.2071 - accuracy: 0.9349 - val_loss: 0.4126 - val_accuracy: 0.8647 - 34ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "11/11 - 0s - loss: 0.2064 - accuracy: 0.9379 - val_loss: 0.4292 - val_accuracy: 0.8588 - 41ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "11/11 - 0s - loss: 0.2051 - accuracy: 0.9334 - val_loss: 0.4113 - val_accuracy: 0.8647 - 32ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "11/11 - 0s - loss: 0.2056 - accuracy: 0.9379 - val_loss: 0.4268 - val_accuracy: 0.8588 - 55ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "11/11 - 0s - loss: 0.2044 - accuracy: 0.9349 - val_loss: 0.4156 - val_accuracy: 0.8647 - 34ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "11/11 - 0s - loss: 0.2026 - accuracy: 0.9364 - val_loss: 0.4326 - val_accuracy: 0.8529 - 32ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "11/11 - 0s - loss: 0.2007 - accuracy: 0.9408 - val_loss: 0.4113 - val_accuracy: 0.8647 - 29ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "11/11 - 0s - loss: 0.1997 - accuracy: 0.9393 - val_loss: 0.4058 - val_accuracy: 0.8647 - 47ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "11/11 - 0s - loss: 0.1999 - accuracy: 0.9393 - val_loss: 0.4358 - val_accuracy: 0.8588 - 34ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "11/11 - 0s - loss: 0.1996 - accuracy: 0.9393 - val_loss: 0.3937 - val_accuracy: 0.8647 - 58ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "11/11 - 0s - loss: 0.1997 - accuracy: 0.9364 - val_loss: 0.4277 - val_accuracy: 0.8529 - 35ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "11/11 - 0s - loss: 0.1975 - accuracy: 0.9408 - val_loss: 0.3932 - val_accuracy: 0.8647 - 32ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "11/11 - 0s - loss: 0.1948 - accuracy: 0.9423 - val_loss: 0.4205 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "11/11 - 0s - loss: 0.1951 - accuracy: 0.9438 - val_loss: 0.4008 - val_accuracy: 0.8647 - 49ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "11/11 - 0s - loss: 0.1935 - accuracy: 0.9408 - val_loss: 0.4069 - val_accuracy: 0.8647 - 31ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "11/11 - 0s - loss: 0.1947 - accuracy: 0.9423 - val_loss: 0.4142 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "11/11 - 0s - loss: 0.1929 - accuracy: 0.9438 - val_loss: 0.4039 - val_accuracy: 0.8647 - 29ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "11/11 - 0s - loss: 0.1912 - accuracy: 0.9453 - val_loss: 0.4085 - val_accuracy: 0.8647 - 33ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "11/11 - 0s - loss: 0.1911 - accuracy: 0.9438 - val_loss: 0.4082 - val_accuracy: 0.8647 - 31ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "11/11 - 0s - loss: 0.1901 - accuracy: 0.9438 - val_loss: 0.4114 - val_accuracy: 0.8588 - 29ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "11/11 - 0s - loss: 0.1910 - accuracy: 0.9408 - val_loss: 0.3896 - val_accuracy: 0.8647 - 29ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "11/11 - 0s - loss: 0.1892 - accuracy: 0.9453 - val_loss: 0.3962 - val_accuracy: 0.8647 - 48ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "11/11 - 0s - loss: 0.1887 - accuracy: 0.9408 - val_loss: 0.4095 - val_accuracy: 0.8588 - 48ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "11/11 - 0s - loss: 0.1872 - accuracy: 0.9438 - val_loss: 0.3883 - val_accuracy: 0.8588 - 37ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "11/11 - 0s - loss: 0.1875 - accuracy: 0.9408 - val_loss: 0.3898 - val_accuracy: 0.8647 - 31ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "11/11 - 0s - loss: 0.1867 - accuracy: 0.9482 - val_loss: 0.4074 - val_accuracy: 0.8588 - 58ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "11/11 - 0s - loss: 0.1880 - accuracy: 0.9393 - val_loss: 0.3759 - val_accuracy: 0.8647 - 30ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "11/11 - 0s - loss: 0.1884 - accuracy: 0.9438 - val_loss: 0.4138 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "11/11 - 0s - loss: 0.1838 - accuracy: 0.9423 - val_loss: 0.3702 - val_accuracy: 0.8647 - 31ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "11/11 - 0s - loss: 0.1842 - accuracy: 0.9467 - val_loss: 0.3963 - val_accuracy: 0.8588 - 28ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "11/11 - 0s - loss: 0.1831 - accuracy: 0.9497 - val_loss: 0.3934 - val_accuracy: 0.8588 - 28ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "11/11 - 0s - loss: 0.1830 - accuracy: 0.9467 - val_loss: 0.3960 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "11/11 - 0s - loss: 0.1824 - accuracy: 0.9423 - val_loss: 0.3860 - val_accuracy: 0.8647 - 29ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "11/11 - 0s - loss: 0.1808 - accuracy: 0.9482 - val_loss: 0.3950 - val_accuracy: 0.8588 - 35ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "11/11 - 0s - loss: 0.1814 - accuracy: 0.9482 - val_loss: 0.3916 - val_accuracy: 0.8588 - 29ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "11/11 - 0s - loss: 0.1797 - accuracy: 0.9497 - val_loss: 0.3803 - val_accuracy: 0.8647 - 30ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "11/11 - 0s - loss: 0.1793 - accuracy: 0.9467 - val_loss: 0.3954 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "11/11 - 0s - loss: 0.1794 - accuracy: 0.9453 - val_loss: 0.3924 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "11/11 - 0s - loss: 0.1789 - accuracy: 0.9482 - val_loss: 0.3679 - val_accuracy: 0.8588 - 28ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "11/11 - 0s - loss: 0.1777 - accuracy: 0.9497 - val_loss: 0.3876 - val_accuracy: 0.8588 - 27ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "11/11 - 0s - loss: 0.1773 - accuracy: 0.9512 - val_loss: 0.3835 - val_accuracy: 0.8588 - 29ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "11/11 - 0s - loss: 0.1784 - accuracy: 0.9438 - val_loss: 0.3948 - val_accuracy: 0.8588 - 37ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "11/11 - 0s - loss: 0.1765 - accuracy: 0.9527 - val_loss: 0.3870 - val_accuracy: 0.8588 - 29ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "11/11 - 0s - loss: 0.1758 - accuracy: 0.9497 - val_loss: 0.3666 - val_accuracy: 0.8647 - 47ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "11/11 - 0s - loss: 0.1772 - accuracy: 0.9423 - val_loss: 0.3699 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "11/11 - 0s - loss: 0.1755 - accuracy: 0.9512 - val_loss: 0.3941 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "11/11 - 0s - loss: 0.1753 - accuracy: 0.9467 - val_loss: 0.3659 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "11/11 - 0s - loss: 0.1743 - accuracy: 0.9512 - val_loss: 0.3836 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "11/11 - 0s - loss: 0.1743 - accuracy: 0.9482 - val_loss: 0.3720 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "11/11 - 0s - loss: 0.1739 - accuracy: 0.9527 - val_loss: 0.3804 - val_accuracy: 0.8588 - 38ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "11/11 - 0s - loss: 0.1749 - accuracy: 0.9423 - val_loss: 0.3558 - val_accuracy: 0.8647 - 34ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "11/11 - 0s - loss: 0.1722 - accuracy: 0.9482 - val_loss: 0.3841 - val_accuracy: 0.8588 - 30ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "11/11 - 0s - loss: 0.1716 - accuracy: 0.9497 - val_loss: 0.3719 - val_accuracy: 0.8588 - 31ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#에폭에 나왔단 로스랑 어큐러씨를 그려본다.(크로스 되는 지점 확인)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig,loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "#loss(오차) 그리기\n",
        "loss_ax.plot(history.history[\"loss\"], \"y\", label = \"train loss\")\n",
        "loss_ax.plot(history.history[\"val_loss\"], \"r\", label = \"val_loss\")\n",
        "loss_ax.set_xlabel(\"epoch\")\n",
        "loss_ax.set_ylabel(\"loss\")\n",
        "loss_ax.legend(loc = \"lower right\") #legend 는 범례 \n",
        "\n",
        "#accuracy(정확도) 그리기\n",
        "acc_ax.plot(history.history[\"accuracy\"], \"b\", label = \"train acc\")\n",
        "acc_ax.plot(history.history[\"val_accuracy\"], \"g\", label = \"val_acc\")\n",
        "acc_ax.set_ylabel(\"accuracy\")\n",
        "acc_ax.legend(loc = \"upper right\") #legend 는 범례 \n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dLpD6Z2K4arZ",
        "outputId": "81d9239c-f6af-42e2-ac4d-3c2b921a9e61"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, validation_split = 0.2, epochs = 20, batch_size = 64, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23U7fH5c7kBL",
        "outputId": "531f0440-bda3-4874-f72f-bfa83f28a590"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1702 - accuracy: 0.9497 - val_loss: 0.3680 - val_accuracy: 0.8588\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.9512 - val_loss: 0.3609 - val_accuracy: 0.8588\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9497 - val_loss: 0.3671 - val_accuracy: 0.8588\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9497 - val_loss: 0.3579 - val_accuracy: 0.8647\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9512 - val_loss: 0.3734 - val_accuracy: 0.8588\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9512 - val_loss: 0.3627 - val_accuracy: 0.8588\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9527 - val_loss: 0.3614 - val_accuracy: 0.8588\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9527 - val_loss: 0.3717 - val_accuracy: 0.8588\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9512 - val_loss: 0.3677 - val_accuracy: 0.8588\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9512 - val_loss: 0.3754 - val_accuracy: 0.8588\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9512 - val_loss: 0.3679 - val_accuracy: 0.8588\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9527 - val_loss: 0.3560 - val_accuracy: 0.8588\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9512 - val_loss: 0.3706 - val_accuracy: 0.8588\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9512 - val_loss: 0.3531 - val_accuracy: 0.8588\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9512 - val_loss: 0.3723 - val_accuracy: 0.8588\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9527 - val_loss: 0.3496 - val_accuracy: 0.8588\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.9497 - val_loss: 0.3620 - val_accuracy: 0.8588\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1653 - accuracy: 0.9497 - val_loss: 0.3627 - val_accuracy: 0.8588\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.9527 - val_loss: 0.3453 - val_accuracy: 0.8647\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9527 - val_loss: 0.3684 - val_accuracy: 0.8588\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51d87ee670>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred  = model.predict(X_test, verbose = 0)\n",
        "Y_class = np.round(Y_pred, 0)\n",
        "train_score = model.evaluate(X_train, Y_train, verbose=0)\n",
        "test_score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Y 예측값 : \\n\", Y_pred[:5])\n",
        "print(\"Y 예측 클래스 : \\n \", Y_class[:5] )\n",
        "print(\"train accuracy : {:.3f}\".format(train_score[0], train_score[1]))\n",
        "print(\"test accuracy : {:.3f}\".format(test_score[0], test_score[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzpzjDf87sMJ",
        "outputId": "b0dd0066-1cde-4eaa-823b-cc73802168e5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y 예측값 : \n",
            " [[0.93126047]\n",
            " [1.        ]\n",
            " [0.0177254 ]\n",
            " [0.01244921]\n",
            " [0.99973166]]\n",
            "Y 예측 클래스 : \n",
            "  [[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "train accuracy : 0.202\n",
            "test accuracy : 0.224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEDE0NKg7o7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KaLpSVuZgZJ4"
      }
    }
  ]
}